# **House Prices - Advanced Regression Techniques**


## Overview

This repository contains the code used for my submission in Kaggle's ongoing predictive analytics [competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). The goal is to predict missing house prices from a test set by training a machine learning model on a training set containing 2900 observations and 79 predictors, ranging from numeric to categorical. The four main data science related tasks performed in my project include cleaning data, exploratory data analysis, feature engineering, and fitting machine learning models. 

## Software and Packages Used
* R v4.0.2, RStudio v1.3.1056
* [tidyverse](https://www.tidyverse.org/packages/) 
    > Import, clean, manipulate, and visualize features
* [corrplot](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) 
    >  Correlation matrix graphic for numeric features
* [gbm](https://cran.r-project.org/web/packages/gbm/gbm.pdf) 
    > For training a boosted linear regression model with customizable iterations, learning rate, and higher-order interactions
* [randomForest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)
    > Used for training a random forest model  
* [glmnet](https://cran.r-project.org/web/packages/glmnet/glmnet.pdf)
    > Used to train regularized regression models (ridge, LASSO, elastic net) 
* [rcmdrmisc](https://cran.r-project.org/web/packages/RcmdrMisc/RcmdrMisc.pdf)
    > Improved summary statistics for numeric features
* [caret](http://topepo.github.io/caret/index.html)
    > Data preprocessing, model fitting with various tuning parameters, and variable importance reports
* [xgboost](https://cran.r-project.org/web/packages/xgboost/xgboost.pdf)
    > An improved implementation of gradient boosting for a variety of ML algorithms with greater speed and accuracy than gbm




